# -*- coding: utf-8 -*-
"""소셜팀플산불시각.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CA6thbdnAhSHSEgOQj7MZRMqu4XR6ywI
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!apt-get install -y fonts-nanum*
!rm -rf /root/.cache/matplotlib/* # 폰트 캐시 재설정
# 런타임 다시 시작 후 실행
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib as mpl
#
path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
font_name = mpl.font_manager.FontProperties(fname=path).get_name()
plt.rcParams['font.family'] = font_name

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import matplotlib.font_manager as fm
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
import geopandas as gpd
from shapely.geometry import Point

df = pd.read_csv("/content/산림청_산불상황관제시스템 산불통계데이터_20241016.csv",encoding="cp949")


df['발생일시_전체'] = pd.to_datetime(
    df['발생일시_년'].astype(str) + '-' +
    df['발생일시_월'].astype(str).str.zfill(2) + '-' +
    df['발생일시_일'].astype(str).str.zfill(2) + ' ' +
    df['발생일시_시간']
)

df['진화종료일시_전체'] = pd.to_datetime(
    df['진화종료시간_년'].astype(str) + '-' +
    df['진화종료시간_월'].astype(str).str.zfill(2) + '-' +
    df['진화종료시간_일'].astype(str).str.zfill(2) + ' ' +
    df['진화종료시간_시간']
)


# timedelta (소요 시간)
df['진화_소요시간'] = (df['진화종료일시_전체'] - df['발생일시_전체'])
df['진화_소요시간_분'] = df['진화_소요시간'].dt.total_seconds() / 60
df['발생시간대']=df['발생일시_시간'].str.split(':').str[0].astype(int)
#df.drop(columns=['발생일시_년','발생일시_월','발생일시_일','발생일시_시간','진화종료시간_년', '진화종료시간_월','진화종료시간_일'], inplace=True)
df.head()

month_counts = df['발생일시_월'].value_counts().sort_index()
month_counts.plot(kind='bar', color='skyblue')
plt.title('월별 산불 발생 건수')
plt.xlabel('월')
plt.ylabel('건수')
plt.xticks(rotation=0)
plt.show()

weekday_order = ['월', '화', '수', '목', '금', '토', '일']
weekday_counts = df['발생일시_요일'].value_counts().reindex(weekday_order)
weekday_counts.plot(kind='bar', color='salmon')
plt.title('요일별 산불 발생 빈도')
plt.xlabel('요일')
plt.ylabel('건수')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.hist(df['발생시간대'], bins=24, color='skyblue', edgecolor='black')
plt.title('시간대별 산불 발생 빈도')
plt.xlabel('시간 (0~23)')
plt.ylabel('발생 건수')
plt.xticks(range(24))
plt.grid(axis='y', alpha=0.75)
plt.show()

region_counts = df['발생장소_시도'].value_counts()
region_counts.plot(kind='barh', color='teal')
plt.title('시도별 산불 발생')
plt.xlabel('건수')
plt.ylabel('시도')
plt.show()

df['발생원인_구분'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)
plt.title('산불 발생원인 구분 비율')
plt.ylabel('')  # 파이차트에서 y축 제거
plt.show()

!apt-get -qq install fonts-nanum > /dev/null # Install the Nanum font package which includes Malgun Gothic
!fc-cache -fv > /dev/null # Clear and rebuild the font cache

import matplotlib.font_manager as fm
from wordcloud import WordCloud # Make sure you have this import
import matplotlib.pyplot as plt

font_path = fm.findfont('NanumGothic')  # Find the path to NanumGothic font

# Assuming '발생원인_기타' column contains the text data for the word cloud
text_data = ' '.join(df['발생원인_기타'].astype(str).tolist()) # extract text data from '발생원인_기타' column

# Now use the font_path and text_data in WordCloud:
wordcloud = WordCloud(font_path=font_path, background_color='white', width=800, height=400).generate(text_data)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('기타 발생원인 워드클라우드')
plt.show()

cause_area = df.groupby('발생원인_구분')['피해면적_합계'].sum().sort_values()
cause_area.plot(kind='barh', color='purple')
plt.title('발생원인별 피해면적 합계')
plt.xlabel('피해면적 (ha)')
plt.show()

df['주소'] = (
    df['발생장소_시도'].fillna('') + ' ' +
    df['발생장소_시군구'].fillna('') + ' ' +
    df['발생장소_읍면'].fillna('') + ' ' +
    df['발생장소_동리'].fillna('')
).str.split().str.join(' ')
df

gdf_sig = gpd.read_file("./sig.shp",encoding='euc-kr')
gdf_sig
unique_regions = gdf_sig['SIG_KOR_NM'].unique()
print(unique_regions)
print(df['발생장소_시군구'].unique())

# Step 1: Clean up region names in df

# Step 2: Standardize regions by creating a mapping dictionary

name_mapping = {

    '고양': '고양시',#and '고양시 덕양구'and'고양시 일산동구'and'고양시 일산서구',
    #'금남': '금남군', shp에 금남은 없음
    '성남': '성남시',#and'성남시 수정구'and'성남시 중원구' and'성남시 분당',
    '안산 상록': '안산시 상록구',
    '안산' : '안산시 단원구',
    '안양': '안양시',#and'안양시 만안구'and'안양시 동안구',
    #'연동': '연동시',  shp에 연동없음
    '용인 처인': '용인시 처인구',
    '용인' : '용인시 기흥구',# and '용인시 수지구',
    '전의': '전주시 전의면', #shp에 없음
    '전주 완산': '전주시 완산구',
    '전주' : '전주시 덕진구',
    '진해': '창원시 진해구',
    '창원 마산합포': '창원시 마산합포구',
    '창원 의창' : '창원시 의창구',
    '창원 마산회원' : '창원시 마산회원구',
    '창원 ' : '창원시 성산구',
    '천안 동남': '천안시 동남구',
    '천안 서북': '천안시 서북구',
    '천안' : '천안시 동남구',#and'천안시 서북구',
    '포항 남': '포항시 남구',
    '포항 북': '포항시 북구',
    '포항' : '포항시 남구' #and '포항시 북구'
}

df['발생장소_시군구'] = df['발생장소_시군구'].replace(name_mapping)

# Step 3: Clean region names in gdf_sig similarly (정제는 shapefile 쪽만)
gdf_sig['SIG_KOR_NM'] = gdf_sig['SIG_KOR_NM'].str.replace(r"시|구|군", "", regex=True).str.strip()

# Step 4: Also remove 시/군/구 from df AFTER mapping (if really needed)
df['발생장소_시군구'] = df['발생장소_시군구'].str.replace(r"시|구|군", "", regex=True).str.strip()
# Step 4: Merge the datasets
merged = gdf_sig.merge(df, left_on='SIG_KOR_NM', right_on='발생장소_시군구', how='left')

# Step 5: Create the 'incident_count' column
merged['incident_count'] = merged.groupby('SIG_KOR_NM')['발생일시_일'].transform('count')

# Step 6: Plot the heatmap
fig, ax = plt.subplots(figsize=(12, 12))
merged.plot(column='incident_count', cmap='YlOrRd', ax=ax,
            edgecolor='black', linewidth=0.5, legend=True,
            vmin=0, vmax=merged['incident_count'].max())
# Step 7: Debugging - Checking for missing regions in the shapefile
df_sgg = df['발생장소_시군구'].fillna('').str.strip().unique()
shp_sgg = gdf_sig['SIG_KOR_NM'].fillna('').str.strip().unique()

# Convert to sets to eliminate duplicates
df_sgg_set = set(df_sgg)
shp_sgg_set = set(shp_sgg)

# Find regions present in df but not in gdf_sig
missing_in_shp = df_sgg_set - shp_sgg_set
print("❌ [DF → SHP] df에는 있지만 shp에 없는 시군구:")
for sgg in sorted(missing_in_shp):
    print("  -", sgg)

#동구 남구 같은곳이 중복되는 현상발생 *********************************************

# 시군구별 화재 발생 건수 집계
top30 = (
    df['발생장소_시군구']
    .value_counts()
    .reset_index()
    .rename(columns={'index': '시군구', '발생장소_시군구': '화재건수'})
    .head(30)
)

# 출력
print("🔥 시군구별 화재 발생 Top 30:")
print(top30.to_string(index=False))


### 북과 같은 이상한 상황 발생 ㅠ
df

import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
import geopandas as gpd
from shapely.geometry import Point
# 지오코더 초기화 및 속도 제한
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# tqdm 적용
tqdm.pandas()

# 지오코딩
print("📍 지오코딩을 시작합니다...")
df['location'] = df['주소'].progress_apply(geocode)

# 위도/경도 분리
df['위도'] = df['location'].apply(lambda loc: loc.latitude if loc else None)
df['경도'] = df['location'].apply(lambda loc: loc.longitude if loc else None)

# 지오코딩 실패 항목 출력
failed = df[df['위도'].isna()]
if not failed.empty:
    print(f"❗ 지오코딩 실패 건수: {len(failed)}")
    print("실패한 주소 예시:")
    print(failed[['주소']].head())

# 유효 좌표만 필터링
df_valid = df.dropna(subset=['위도', '경도'])

# GeoDataFrame 생성
# 유효 좌표만 필터링
df_valid = df.dropna(subset=['위도', '경도'])

gdf = gpd.GeoDataFrame(df_valid, geometry=gpd.points_from_xy(df_valid['경도'], df_valid['위도']))
gdf.set_crs(epsg=4326, inplace=True)

# 결과 저장
df.to_csv("./산불_지오코딩_전체결과.csv", index=False, encoding='utf-8-sig')
print("✅ 전체 지오코딩 결과가 '산불_지오코딩_전체결과.csv'에 저장되었습니다.")

df_success = df[df['위도'].notna()].copy()
df_fail = df[df['위도'].isna()].copy()

# 샘플로 5개씩 출력해 보기
print("✅ 지오코딩 성공 주소 예시:")
print(df_success['주소'].head())

print("\n❌ 지오코딩 실패 주소 예시:")
print(df_fail['주소'].head())

import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. 기존 결과 불러오기
df = pd.read_csv("./산불_지오코딩_전체결과.csv", encoding="utf-8-sig")

# 2. 지오코딩 실패한 행만 분리
df_fail = df[df['위도'].isna()].copy()
df_success = df[df['위도'].notna()].copy()
print(f"❗ 지오코딩 실패 건수: {len(df_fail)}")

# 3. 주소 보정 함수 정의
def build_full_address(row):
    parts = []

    # 시도
    시도 = row.get('발생장소_시도')
    if pd.notna(시도):
        parts.append(시도)

    # 시군구
    시군구 = row.get('발생장소_시군구')
    if pd.notna(시군구):
        if not 시군구.endswith(('시', '군', '구')):
            시군구 += '시'  # 기본값은 시
        parts.append(시군구)

    # 읍면
    읍면 = row.get('발생장소_읍면')
    if pd.notna(읍면):
        if not 읍면.endswith(('읍', '면', '동')):
            읍면 += '면'  # 대부분 면으로 가정
        parts.append(읍면)

    # 동리
    동리 = row.get('발생장소_동리')
    if pd.notna(동리):
        if not 동리.endswith(('리', '동')):
            동리 += '리'
        parts.append(동리)

    return ' '.join(parts)

# 4. 주소 보정
df_fail['주소_보정'] = df_fail.apply(build_full_address, axis=1)
# 5. 지오코딩 준비
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 6. 보정 주소로 지오코딩 재시도
print("📍 보정된 주소로 지오코딩 재시작...")
df_fail['location'] = df_fail['주소_보정'].progress_apply(geocode)
df_fail['위도'] = df_fail['location'].apply(lambda loc: loc.latitude if loc else None)
df_fail['경도'] = df_fail['location'].apply(lambda loc: loc.longitude if loc else None)

# 7. 성공 데이터 + 재시도 성공 데이터 병합
df_final = pd.concat([df_success, df_fail], ignore_index=True)

# 8. 결과 저장
df_final.to_csv("./산불_지오코딩_보정결과.csv", index=False, encoding='utf-8-sig')
print("✅ 최종 지오코딩 결과가 '산불_지오코딩_보정결과.csv'에 저장되었습니다.")

df_retry

"""
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. 보정된 주소 결과 불러오기
df = pd.read_csv("./산불_지오코딩_보정결과.csv", encoding="utf-8-sig")

# 2. 지오코딩 실패 + 보정주소 있는 행만 필터링
df_retry = df[(df['주소_보정'].notna()) & (df['위도'].isna())].copy()
print(f"📌 재보정 대상 건수: {len(df_retry)}")

# 3. 대한민국 붙이기 (주소 인식률 향상)
df_retry.loc[:, '주소_보정_최종'] = df_retry['주소_보정'].astype(str) + ' 대한민국'

# 4. Nominatim 설정
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 5. 재지오코딩
print("📍 재지오코딩 중...")
df_retry['location'] = df_retry['주소_보정_최종'].progress_apply(geocode)
df_retry['위도'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['경도'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)

# 6. 원본에서 재시도 대상 제거 후 병합
df_keep = df[~df.index.isin(df_retry.index)]
df_final = pd.concat([df_keep, df_retry], ignore_index=True)

# 7. 저장
df_final.to_csv('./산불_지오코딩_최종결과.csv', index=False, encoding='utf-8-sig')
print("✅ 재보정 및 병합 완료 → '산불_지오코딩_최종결과.csv' 저장됨")
"""

"""
!pip install geokakao

import pandas as pd
import geokakao as gk
from tqdm import tqdm
import time
import requests

# ✅ 카카오 REST API 키 입력 (반드시 본인 키로 교체)
KAKAO_API_KEY = "bb589f5598d656483016cc22a3fb3e22"

# CSV 불러오기
df = pd.read_csv('./산불_지오코딩_최종결과.csv', encoding='utf-8-sig')

# 주소 접미사 붙이는 함수 정의
def suffix_addr(row):
    sido = str(row['발생장소_시도']).strip()
    sigungu = str(row['발생장소_시군구']).strip()
    eupmyeon = str(row['발생장소_읍면']).strip()
    dongri = str(row['발생장소_동리']).strip()

    if eupmyeon and not eupmyeon.endswith(('면', '동', '리')):
        eupmyeon += '동'
    if dongri and not dongri.endswith(('면', '동', '리')):
        dongri += '리'

    parts = [sido, sigungu, eupmyeon, dongri]
    parts = [p for p in parts if p and p.lower() != 'nan']
    return ' '.join(parts)

# 접미사 붙인 주소 컬럼 생성
df['주소_접미사'] = df.apply(suffix_addr, axis=1)

# 지오코딩 실패 주소만 추출 (기존 '위도'가 NaN이면서, 주소_접미사 있는 행)
df_retry = df[df['위도'].isna() & df['주소_접미사'].notna()].copy()
print(f"📍 카카오 재시도 대상: {len(df_retry)}건")

# 위도/경도 초기화
df_retry['위도'] = None
df_retry['경도'] = None

# 1차: geokakao로 재시도
for idx, row in tqdm(df_retry.iterrows(), total=len(df_retry)):
    try:
        single_df = pd.DataFrame([row])
        result_df = gk.add_coordinates_to_dataframe(single_df, '주소_접미사')
        if result_df is not None and not result_df.empty:
            lat = result_df.at[0, '위도'] if '위도' in result_df.columns else None
            lng = result_df.at[0, '경도'] if '경도' in result_df.columns else None
            if lat and lng:
                df_retry.at[idx, '위도'] = lat
                df_retry.at[idx, '경도'] = lng
            else:
                print(f"❗ 실패(좌표 없음): {row['주소_접미사']}")
        else:
            print(f"❗ 실패(빈 결과): {row['주소_접미사']}")
    except Exception as e:
        print(f"❗ 실패(에러): {row['주소_접미사']} → {e}")
    time.sleep(0.3)

# 2차: 단계별 주소 간략화 재시도 함수
def get_kakao_coord(address, api_key):
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {api_key}"}
    params = {"query": address}
    resp = requests.get(url, headers=headers, params=params)
    if resp.status_code == 200:
        documents = resp.json().get('documents')
        if documents:
            x = documents[0].get('x')
            y = documents[0].get('y')
            return float(y), float(x)
    return None, None

def try_address_variants(row, api_key):
    sido = row['발생장소_시도']
    sigungu = row['발생장소_시군구']
    eupmyeon = row['발생장소_읍면']
    dongri = row['발생장소_동리']

    if eupmyeon and not eupmyeon.endswith(('면','동','리')):
        eupmyeon += '동'
    if dongri and not dongri.endswith(('면','동','리')):
        dongri += '리'

    address_list = [
        f"{sido} {sigungu} {eupmyeon} {dongri}".strip(),
        f"{sido} {sigungu} {eupmyeon}".strip(),
        f"{sido} {sigungu}".strip(),
        f"{sido}".strip()
    ]

    for addr in address_list:
        lat, lng = get_kakao_coord(addr, api_key)
        if lat and lng:
            return lat, lng
    return None, None

# geokakao 1차 시도 후에도 실패한 데이터 대상으로 2차 재시도
df_retry2 = df_retry[df_retry['위도'].isna() | df_retry['경도'].isna()].copy()

for idx, row in tqdm(df_retry2.iterrows(), total=len(df_retry2)):
    lat, lng = try_address_variants(row, KAKAO_API_KEY)
    if lat and lng:
        df_retry.at[idx, '위도'] = lat
        df_retry.at[idx, '경도'] = lng
    else:
        print(f"❗ 실패(빈 결과): {row['발생장소_시도']} {row['발생장소_시군구']} {row['발생장소_읍면']} {row['발생장소_동리']}")
    time.sleep(0.3)

# 기존 좌표 잘 나온 데이터 + 재시도 결과 병합
df_final = pd.concat([df[~df.index.isin(df_retry.index)], df_retry], ignore_index=True)

# 저장
df_final.to_csv('./산불_지오코딩_카카오보정_최종결과.csv', index=False, encoding='utf-8-sig')
print("✅ 카카오 보정 완료 → '산불_지오코딩_카카오보정_최종결과.csv'")

import pandas as pd
import geopandas as gpd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm
"""
# -----------------------------
# 📌 시군구 보정 딕셔너리
# -----------------------------
sgg_mapping = {

    '고양': '고양시',#and '고양시 덕양구'and'고양시 일산동구'and'고양시 일산서구',
    #'금남': '금남군', shp에 금남은 없음
    '성남': '성남시',#and'성남시 수정구'and'성남시 중원구' and'성남시 분당',
    '안산 상록': '안산시 상록구',
    '안산' : '안산시 단원구',
    '안양': '안양시',#and'안양시 만안구'and'안양시 동안구',
    #'연동': '연동시',  shp에 연동없음
    '용인 처인': '용인시 처인구',
    '용인' : '용인시 기흥구',# and '용인시 수지구',
    '전의': '전주시 전의면', #shp에 없음
    '전주 완산': '전주시 완산구',
    '전주' : '전주시 덕진구',
    '진해': '창원시 진해구',
    '창원 마산합포': '창원시 마산합포구',
    '창원 의창' : '창원시 의창구',
    '창원 마산회원' : '창원시 마산회원구',
    '창원 ' : '창원시 성산구',
    '천안 동남': '천안시 동남구',
    '천안 서북': '천안시 서북구',
    '천안' : '천안시 동남구',#and'천안시 서북구',
    '포항 남': '포항시 남구',
    '포항 북': '포항시 북구',
    '포항' : '포항시 남구' #and '포항시 북구'
}
def generate_address(row):
    sido = str(row['발생장소_시도']).strip()
    sgg = str(row['발생장소_시군구']).strip()
    eupmyeon = str(row['발생장소_읍면']) if pd.notnull(row['발생장소_읍면']) else ''
    dongri = str(row['발생장소_동리']) if pd.notnull(row['발생장소_동리']) else ''

    full_sgg = sgg_mapping.get(sgg, sgg)
    address = f"{sido} {full_sgg} {eupmyeon} {dongri}".strip()
    return address

# 3. CSV 불러오기
df = pd.read_csv('./산불_지오코딩_최종결과.csv', encoding='utf-8-sig')

# 4. 시군구 보정 후 주소 재생성
df['주소'] = df.apply(generate_address, axis=1)

# 5. 지오코더 초기화 및 RateLimiter 설정
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# 6. 위도/경도 없는 행만 필터링해서 재시도
df_retry = df[df['위도'].isna()].copy()

tqdm.pandas()
df_retry['location'] = df_retry['주소'].progress_apply(geocode)

# 7. 좌표 다시 채우기
df_retry['위도'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['경도'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)

# 8. 기존 df 에 재시도 결과 병합
df.update(df_retry[['위도', '경도']])

# 9. 좌표 없는 행 확인 (필요시 로그 출력 및 파일 저장)
missing = df[df['위도'].isna()]
print(f"지오코딩 실패 주소 수: {len(missing)}")
if len(missing) > 0:
    print("❗️ 지오코딩 실패한 주소 목록:")
    for addr in missing['주소']:
        print(f" - {addr}")
# 10. GeoDataFrame 생성 (필요 시)
gdf = gpd.GeoDataFrame(df.dropna(subset=['위도', '경도']), geometry=gpd.points_from_xy(df['경도'], df['위도']))
gdf.set_crs(epsg=4326, inplace=True)

# 11. 최종 결과 저장
df.to_csv('./산불_지오코딩_최종_재보정_결과.csv', index=False, encoding='utf-8-sig')
print("✅ 최종 재보정 결과 저장 완료: '산불_지오코딩_최종_재보정_결과.csv'")
"""

#----------------------------------------------------------------

"""
# -----------------------------
# 📌 주소 생성 함수
# -----------------------------
def generate_address(row):
    sido = str(row['발생장소_시도']).strip()
    sgg = str(row['발생장소_시군구']).strip()
    eupmyeon = str(row['발생장소_읍면']) if pd.notnull(row['발생장소_읍면']) else ''
    dongri = str(row['발생장소_동리']) if pd.notnull(row['발생장소_동리']) else ''

    # 시군구 매핑
    full_sgg = sgg_mapping.get(sgg, sgg)
    address = f"{sido} {full_sgg} {eupmyeon} {dongri}".strip()
    return address

# -----------------------------
# 📌 지오코딩 전체 처리 함수
# -----------------------------

# 지오코더 초기화
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# tqdm으로 진행 표시
tqdm.pandas()
df['location'] = df['주소'].progress_apply(geocode)

# 위도/경도 컬럼 분리
df['위도'] = df['location'].apply(lambda loc: loc.latitude if loc else None)
df['경도'] = df['location'].apply(lambda loc: loc.longitude if loc else None)

# 유효 좌표만 필터링
df = df.dropna(subset=['위도', '경도'])

# GeoDataFrame 생성
gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['경도'], df['위도']))
gdf.set_crs(epsg=4326, inplace=True)
# 지오코딩 결과 저장

df.to_csv("./산불_지오코딩_결과.csv", index=False, encoding='utf-8-sig')
print("✅ 지오코딩 결과가 '산불_지오코딩_결과.csv'에 저장되었습니다.")

"""
import pandas as pd
import geopandas as gpd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# -----------------------------
# 📌 시군구 보정 딕셔너리
# -----------------------------
"""
sgg_mapping = {
    '고양': '고양시',
    '성남': '성남시',
    '안산 상록': '안산시 상록구',
    '안산': '안산시 단원구',
    '안양': '안양시',
    '용인 처인': '용인시 처인구',
    '용인': '용인시 기흥구',
    '전주 완산': '전주시 완산구',
    '전주': '전주시 덕진구',
    '진해': '창원시 진해구',
    '창원 마산합포': '창원시 마산합포구',
    '창원 마산회원': '창원시 마산회원구',
    '창원 의창': '창원시 의창구',
    '창원': '창원시 성산구',
    '천안 동남': '천안시 동남구',
    '천안 서북': '천안시 서북구',
    '천안': '천안시 동남구',
    '포항 남': '포항시 남구',
    '포항 북': '포항시 북구',
    '포항': '포항시 남구'
}
"""
# -----------------------------
# 📌 주소 생성 함수
# -----------------------------
def generate_address(row):
    sido = str(row['발생장소_시도']).strip()
    sgg = str(row['발생장소_시군구']).strip()
    eupmyeon = str(row['발생장소_읍면']).strip() if pd.notnull(row['발생장소_읍면']) else ''
    dongri = str(row['발생장소_동리']).strip() if pd.notnull(row['발생장소_동리']) else ''

    # 읍면이 없고 동리만 있을 때 → 동리를 읍면으로 사용
    if eupmyeon == '' and dongri != '':
        eupmyeon = dongri
        dongri = ''

    # 읍면 접미사 붙이기
    if eupmyeon and not eupmyeon.endswith(('읍', '면', '동')):
        eupmyeon += '면'  # 기본값으로 '면' 붙이기

    # full_sgg가 누락되어서 변수 에러 납니다. 아래는 간단히 sgg만 사용했습니다.
    return f"{sido} {sgg} {eupmyeon}".strip()  # 동리는 제외

# -----------------------------
# 📌 지오코딩 시도 함수 (실시간 로그 출력)
# -----------------------------
def try_geocode(addr):
    try:
        loc = geocode(addr)
        if loc is None:
            print(f"❌ 실패: {addr}")
        else:
            print(f"✅ 성공: {addr} → {loc.address}")  # 전체 주소 출력 추가
        return loc
    except Exception as e:
        print(f"⚠️ 오류: {addr} | {e}")
        return None

# 1. CSV 불러오기
df = pd.read_csv('./산불_지오코딩_최종결과.csv', encoding='utf-8-sig')

# 2. 주소 생성
df['주소'] = df.apply(generate_address, axis=1)

# 3. 지오코더 초기화 및 RateLimiter 설정
geolocator = Nominatim(user_agent="fire-mapper")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

# 4. 위도/경도 없는 행만 필터링
df_retry = df[df['위도'].isna()].copy()

# 5. 지오코딩 수행 (실시간 콘솔 로그 포함)
tqdm.pandas()
df_retry['location'] = df_retry['주소'].progress_apply(try_geocode)

# 6. 좌표 및 전체 주소 채우기
df_retry['위도'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['경도'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)
df_retry['location'] = df_retry['location'].apply(lambda loc: loc.address if loc else None)
# 7. 원본 df에 업데이트
df.update(df_retry[['위도', '경도', 'location']])

# 8. 실패 주소 최종 출력
missing = df[df['위도'].isna()]
print(f"\n🚨 최종 지오코딩 실패 주소 수: {len(missing)}")
if len(missing) > 0:
    print("📍 실패한 주소 목록:")
    for addr in missing['주소']:
        print(f" - {addr}")

# 9. GeoDataFrame 생성 (선택 사항)
try:
    gdf = gpd.GeoDataFrame(df.dropna(subset=['위도', '경도']), geometry=gpd.points_from_xy(df['경도'], df['위도']))
    gdf.set_crs(epsg=4326, inplace=True)
except Exception as e:
    print(f"⚠️ GeoDataFrame 생성 오류: {e}")

# 10. 결과 저장
df.to_csv('./산불_지오코딩_최종_재보정_결과.csv', index=False, encoding='utf-8-sig')
print("\n✅ 최종 재보정 결과 저장 완료: '산불_지오코딩_최종_재보정_결과.csv'")

#지오코딩으로 완벽한 주소 넣기


from geopy.extra.rate_limiter import RateLimiter

# 리버스 지오코더 초기화
reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)

# 1. 위도/경도는 있으나 location이 비어 있는 경우
df_reverse = df[(df['위도'].notna()) & (df['경도'].notna()) & (df['location'].isna())].copy()

# 2. 리버스 지오코딩 함수
def try_reverse_geocode(lat, lon):
    try:
        loc = reverse((lat, lon))
        if loc is None:
            print(f"❌ 리버스 실패: {lat}, {lon}")
        else:
            print(f"✅ 리버스 성공: {lat}, {lon} → {loc.address}")
        return loc.address if loc else None
    except Exception as e:
        print(f"⚠️ 오류: {lat}, {lon} | {e}")
        return None

# 3. location 채우기
tqdm.pandas()
df_reverse['location'] = df_reverse.progress_apply(lambda row: try_reverse_geocode(row['위도'], row['경도']), axis=1)

# 4. 원본 df 업데이트
df.update(df_reverse[['location']])

df.drop(columns=['주소_보정', '주소_보정_최종'], inplace=True, errors='ignore')

df.to_csv('./산불_지오코딩_완전최종_재보정_결과.csv', index=False, encoding='utf-8-sig')
print("\n✅ 최종 재보정 결과 저장 완료: '산불_지오코딩_최종_재보정_결과.csv'")

"""
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

# 1. 이전 결과 파일 불러오기
df = pd.read_csv('./산불_지오코딩_최종_재보정_결과.csv', encoding='utf-8-sig')

# 2. 위도/경도 없는 행만 추출
df_retry = df[df['위도'].isna()].copy()

def generate_full_address(row):
    sido = str(row['발생장소_시도']).strip()
    sgg = str(row['발생장소_시군구']).strip()
    dongri = str(row['발생장소_동리']).strip() if pd.notnull(row['발생장소_동리']) else ''

    # 시군구가 비어있지 않고, "구"가 없으면 "구" 붙임
    if sgg and not sgg.endswith('구'):
        sgg += '구'

    # 동리가 비어있지 않고, "동"이 없으면 "동" 붙임
    if dongri and not dongri.endswith('동'):
        dongri += '동'

    # 읍면은 무시하고, 주소 합치기 (띄어쓰기 주의)
    address = f"{sido} {sgg} {dongri}".strip()
    return address

# 적용 예시
df['주소'] = df.apply(generate_full_address, axis=1)
# 4. 지오코딩 준비
geolocator = Nominatim(user_agent="fire-mapper-ri")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)
tqdm.pandas()

# 5. 지오코딩 시도
def try_geocode(address):
    location = geocode(address)
    if location:
        print(f"✅ 성공: {address}")
    else:
        print(f"❌ 실패: {address}")
    return location

df_retry['위도'] = df_retry['location'].apply(lambda loc: loc.latitude if loc else None)
df_retry['경도'] = df_retry['location'].apply(lambda loc: loc.longitude if loc else None)
df_retry['location'] = df_retry['location'].apply(lambda loc: loc.address if loc else None)

# 7. 원본 df에 업데이트
df.update(df_retry[['위도', '경도', 'location']])

# 7. 다시 저장
df.to_csv('./산불_지오코딩_최종_재보정_최종_결과.csv', index=False, encoding='utf-8-sig')
print("✅ '읍' 붙여서 재시도 결과 저장 완료")

"""

pip install geopandas pandas folium matplotlib shapely

df_filtered = df.dropna(subset=['위도', '경도']).copy() # Filter first and create a copy
gdf_points = gpd.GeoDataFrame(
    df_filtered, # Use the filtered DataFrame for data
    geometry=gpd.points_from_xy(df_filtered['경도'], df_filtered['위도']) # Use the filtered DataFrame for geometry
)
gdf_points.set_crs(epsg=4326, inplace=True)
gdf_points
gdf=gdf_points

import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
from shapely.geometry import Point

# 1. 대한민국 시군구 shp 파일 불러오기
shp_path = '/content/sig.shp'  # 시군구 경계파일 경로
gdf_admin = gpd.read_file(shp_path,encoding='euc-kr')


# 2. 위경도 데이터 불러오기
geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. 시군구 Shapefile 좌표계 설정 및 변환
gdf_admin.set_crs(epsg=5179, inplace=True)
gdf_admin = gdf_admin.to_crs(epsg=4326)  # WGS84로 맞춤

# 4. Spatial Join
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 5. 시군구별 히트맵 집계
heatmap = joined.groupby('SIG_KOR_NM').size().reset_index(name='count')
gdf_admin_heatmap = gdf_admin.merge(heatmap, on='SIG_KOR_NM', how='left')
gdf_admin_heatmap['count'] = gdf_admin_heatmap['count'].fillna(0)

# 6. 시각화
fig, ax = plt.subplots(1, 1, figsize=(12, 14))
gdf_admin_heatmap.plot(column='count', ax=ax, legend=True, cmap='OrRd', edgecolor='gray')
plt.title('시군구별 위치 데이터 히트맵', fontsize=16)
plt.axis('off')
plt.tight_layout()
plt.show()

import folium
from folium.plugins import HeatMap
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. 데이터 불러오기
shp_path = '/content/sig.shp'
gdf_admin = gpd.read_file(shp_path, encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# 2. 포인트 CSV 로드

geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Folium 지도 생성
m = folium.Map(location=[36.5, 127.5], zoom_start=6, tiles='cartodbpositron')

# 4. 포인트 히트맵 추가
heat_data = [[point.y, point.x] for point in gdf_points.geometry]
HeatMap(heat_data).add_to(m)

# 포인트마다 마커 추가
for _, row in gdf.iterrows():
    tooltip = f"{row['주소']}<br>피해면적: {row['피해면적_합계']} ha"
    folium.CircleMarker(
        location=[row['위도'], row['경도']],
        radius=4,
        color='red',
        fill=True,
        fill_opacity=0.6,
        tooltip=tooltip
    ).add_to(m)

m.save('folium_markers.html')
m

import folium
from folium import Choropleth
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. 시군구 행정경계 로드 및 좌표계 설정
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# 2. 위경도 데이터 로드 및 GeoDataFrame 생성
geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Spatial Join (어느 시군구에 속하는지)
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. 시군구별 피해면적 합계 집계
damage_by_admin = joined.groupby('SIG_KOR_NM')['피해면적_합계'].sum().reset_index()
damage_by_admin.columns = ['SIG_KOR_NM', 'total_damage']

# 5. 시군구 GeoDataFrame과 병합
gdf_admin = gdf_admin.merge(damage_by_admin, on='SIG_KOR_NM', how='left')
gdf_admin['total_damage'] = gdf_admin['total_damage'].fillna(0)

# 6. Folium 지도 생성
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 7. 시군구 경계 색상 입히기 (Choropleth)
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', 'total_damage'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='시군구별 피해면적 (ha)'
).add_to(m)

# 8. 툴팁 및 경계선에 팝업 추가
for _, row in gdf_admin.iterrows():
    tooltip = f"{row['SIG_KOR_NM']}<br>피해면적: {row['total_damage']} ha"
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {
            'fillColor': '#ffffff00',
            'color': 'black',
            'weight': 0.5,
            'fillOpacity': 0
        },
        tooltip=tooltip
    ).add_to(m)

# 9. 저장
m.save('folium_admin_colormap.html')
m

#울진군이 너무 많이나와서 빼고하는 코드
import folium
from folium import Choropleth
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

# 1. 시군구 행정경계 로드 및 좌표계 설정
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

# ✅ 울진군 제외 ********************************************
gdf_admin = gdf_admin[gdf_admin['SIG_KOR_NM'] != '울진군']

# 2. 위경도 데이터 로드 및 GeoDataFrame 생성
geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')

# 3. Spatial Join (어느 시군구에 속하는지)
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. 시군구별 피해면적 합계 집계
damage_by_admin = joined.groupby('SIG_KOR_NM')['피해면적_합계'].sum().reset_index()
damage_by_admin.columns = ['SIG_KOR_NM', 'total_damage']

# 5. 시군구 GeoDataFrame과 병합
gdf_admin = gdf_admin.merge(damage_by_admin, on='SIG_KOR_NM', how='left')
gdf_admin['total_damage'] = gdf_admin['total_damage'].fillna(0)

# 6. Folium 지도 생성
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 7. Choropleth 추가
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', 'total_damage'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='시군구별 피해면적 (ha)'
).add_to(m)

# 8. 툴팁 추가
for _, row in gdf_admin.iterrows():
    tooltip = f"{row['SIG_KOR_NM']}<br>피해면적: {row['total_damage']} ha"
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {
            'fillColor': '#ffffff00',
            'color': 'black',
            'weight': 0.5,
            'fillOpacity': 0
        },
        tooltip=tooltip
    ).add_to(m)

# 9. 저장
m.save('folium_admin_colormap_without_uljin.html')
m

# 시군구별 피해면적 집계 (피해합계와 횟수)
damage_stats = joined.groupby('SIG_KOR_NM').agg(
    피해면적_합계=('피해면적_합계', 'sum'),
    피해_횟수=('피해면적_합계', 'count')
).reset_index()

# 정렬된 표 보기
damage_stats_sorted = damage_stats.sort_values(by='피해면적_합계', ascending=False)

# 상위 10개만 미리 보기
print(damage_stats_sorted.head(10))

import folium
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point
from folium.plugins import HeatMap

# 1. 데이터 불러오기
gdf_admin = gpd.read_file('/content/sig.shp', encoding='euc-kr')
gdf_admin.crs = 'EPSG:5179'
gdf_admin = gdf_admin.to_crs(epsg=4326)

#*******************************************************************
gdf_admin = gdf_admin[gdf_admin['SIG_KOR_NM'] != '울진군']


# 2. GeoDataFrame 변환
geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')


# 3. 시군구 Spatial Join
joined = gpd.sjoin(gdf_points, gdf_admin, how='left', predicate='within')

# 4. 시군구별 피해 집계
damage_stats = joined.groupby('SIG_KOR_NM').agg(
    피해면적_합계=('피해면적_합계', 'sum'),
    피해_횟수=('피해면적_합계', 'count')
).reset_index()
gdf_admin = gdf_admin.merge(damage_stats, on='SIG_KOR_NM', how='left')
gdf_admin[['피해면적_합계', '피해_횟수']] = gdf_admin[['피해면적_합계', '피해_횟수']].fillna(0)

# 5. 지도 생성
m = folium.Map(location=[36.5, 127.5], zoom_start=7, tiles='cartodbpositron')

# 6. Choropleth: 시군구별 피해면적
folium.Choropleth(
    geo_data=gdf_admin,
    data=gdf_admin,
    columns=['SIG_KOR_NM', '피해면적_합계'],
    key_on='feature.properties.SIG_KOR_NM',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.4,
    legend_name='산불 피해면적 합계 (ha)',
).add_to(m)

# 7. 시군구 팝업 추가
for _, row in gdf_admin.iterrows():
    tooltip = (
        f"<b>{row['SIG_KOR_NM']}</b><br>"
        f"피해면적: {row['피해면적_합계']:.2f} ha<br>"
        f"피해 횟수: {int(row['피해_횟수'])}회"
    )
    folium.GeoJson(
        row['geometry'],
        style_function=lambda x: {'fillColor': '#00000000', 'color': 'black', 'weight': 0.4},
        tooltip=tooltip
    ).add_to(m)

# 8. 히트맵 레이어 추가
heat_data = [[row['위도'], row['경도']] for _, row in df.iterrows()]
HeatMap(heat_data, radius=10, blur=15, min_opacity=0.3).add_to(m)

# 9. 산불 위치 마커 추가
for _, row in df.iterrows():
    tooltip = f"{row['주소']}<br>피해면적: {row['피해면적_합계']} ha"
    folium.CircleMarker(
        location=[row['위도'], row['경도']],
        radius=4,
        color='red',
        fill=True,
        fill_opacity=0.7,
        tooltip=tooltip
    ).add_to(m)

# 10. 저장
m.save('wildfire_map.html')

m



df.to_csv('./지오코딩완전체.csv', index=False, encoding='utf-8-sig')
print("\n✅ 최종 재보정 결과 저장 완료: '지오코딩완전체.csv'")

df = pd.read_csv('./지오코딩완전체.csv', encoding='utf-8-sig')
df

sig = gpd.read_file('/content/sig.shp', encoding='euc-kr')
sig

import geopandas as gpd
import pandas as pd
from shapely.geometry import Point

sig = gpd.read_file('/content/sig.shp', encoding='euc-kr')
sig.set_crs(epsg=5179, inplace=True)
sig = sig.to_crs('EPSG:4326')

geometry = [Point(xy) for xy in zip(df['경도'], df['위도'])]
gdf_points = gpd.GeoDataFrame(df.copy(), geometry=geometry, crs='EPSG:4326')

# 4. Spatial Join: 각 포인트가 어느 시군구에 속하는지
joined = gpd.sjoin(gdf_points, sig[['SIG_KOR_NM', 'SIG_CD', 'SIG_ENG_NM', 'geometry']],
                   how='left', predicate='within')

# 5. 결과 정리 (필요한 열만 남기기)
df_merged = joined.drop(columns='geometry')  # 포인트 geometry 제거

missing = joined[joined['SIG_KOR_NM'].isna()]
print(missing[['위도', '경도', 'location']])

# 부산 강서구 (중복 3개)
for idx in [281, 285, 348]:
    joined.loc[idx, 'SIG_KOR_NM'] = '강서구'
    joined.loc[idx, 'SIG_CD'] = '26440'
    joined.loc[idx, 'SIG_ENG_NM'] = 'Gangseo-gu'

# 경남 거제시 (중복 4개: 682, 733, 942, 1129)
for idx in [682, 733, 942, 1129]:
    joined.loc[idx, 'SIG_KOR_NM'] = '거제시'
    joined.loc[idx, 'SIG_CD'] = '48880'
    joined.loc[idx, 'SIG_ENG_NM'] = 'Geoje-si'

# 전북 부안군 (1개)
joined.loc[983, 'SIG_KOR_NM'] = '부안군'
joined.loc[983, 'SIG_CD'] = '45640'
joined.loc[983, 'SIG_ENG_NM'] = 'Buan-gun'

# 경기 안산시 단원구 (1개)
joined.loc[60, 'SIG_KOR_NM'] = '단원구'
joined.loc[60, 'SIG_CD'] = '41273'
joined.loc[60, 'SIG_ENG_NM'] = 'Danwon-gu'

df_merged = joined.drop(columns=['geometry', 'index_right'])

# 혹시 모를 누락 다시 체크
print(df_merged['SIG_KOR_NM'].isna().sum())  # 0이어야 정상



df_merged.to_csv('./지오코딩및시군구코드.csv', index=False, encoding='utf-8-sig')
print("\n✅ 최종 재보정 결과 저장 완료: '지오코딩및시군구코드.csv'")

df_merged = pd.read_csv('./지오코딩및시군구코드.csv', encoding='utf-8-sig')

#피해면적 산불횟수 2x2 top5개 뽑기
#기준하나 정해보자
#가정하고들어가면 횟수가 중요할듯?
#침엽수가 가지고 있는 비율이 많을때 피해횟수가 많다.
#횟수도 덤으로 하자

#침엽수 비율 많은 지역이 피해정도가 큰가? """"
#침엽수가 많을수록 발생횟수가 많은가? """"
#>이후로 많은 지역찾아서 화재발생 가능성이 있다
#top몇개뽑아서 결론 도출

#침엽수가 더 비싸다 //   실질적 이유조사하기
#산불데이터 너무 적음

#원인 침엽수가 잘탄다 --


#산불, 평균 다해보고
#1. 상관분석 피어슨 ---유의미하다고 나와야함
#산림비율   종속: 산불횟수, 면적, 평균
#->> 다음 해보고싶은거 다해보고

#한달에 몇번 일어났나
#월별 몇회도 추가해라

#sig_cd이걸로 맞춰서 '구' 로 깔끔하게 나오게 df만들어기

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# seaborn 스타일 설정
sns.set(style="whitegrid")
plt.rcParams['font.family'] = 'NanumGothic'  # 한글 폰트 (Colab에서는 'NanumGothic')

# 1. 피해면적 상위 30개 시군구
top_damage = df_merged.groupby('SIG_KOR_NM')['피해면적_합계'].sum().sort_values(ascending=False).head(30)
plt.figure(figsize=(12, 8))
sns.barplot(x=top_damage.values, y=top_damage.index, palette='Reds_r')
plt.title('피해면적 상위 30개 시군구 (단위: ha)')
plt.xlabel('피해면적 합계 (ha)')
plt.ylabel('시군구')
plt.tight_layout()
plt.show()

# 2. 산불 횟수 상위 30개 시군구
top_counts = df_merged['SIG_KOR_NM'].value_counts().head(30)
plt.figure(figsize=(12, 8))
sns.barplot(x=top_counts.values, y=top_counts.index, palette='Blues_r')
plt.title('산불 발생 횟수 상위 30개 시군구')
plt.xlabel('산불 발생 횟수')
plt.ylabel('시군구')
plt.tight_layout()
plt.show()

# 3. 월별 산불 발생 횟수
df_merged['발생일시_월'] = pd.to_numeric(df_merged['발생일시_월'], errors='coerce')  # 혹시 문자열이면 변환
monthly_counts = df_merged['발생일시_월'].value_counts().sort_index()
plt.figure(figsize=(10, 6))
sns.barplot(x=monthly_counts.index, y=monthly_counts.values, palette='Set3')
plt.title('월별 산불 발생 횟수')
plt.xlabel('월')
plt.ylabel('발생 횟수')
plt.xticks(range(0, 12), labels=[f"{i+1}월" for i in range(12)])
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'NanumGothic'
top_n = 5

# 월별 루프
for month in range(1, 13):
    monthly_df = df_merged[df_merged['발생일시_월'] == month]
    top_regions = (
        monthly_df.groupby('SIG_KOR_NM')
        .size()
        .sort_values(ascending=False)
        .head(top_n)
    )

    plt.figure(figsize=(10, 6))
    sns.barplot(x=top_regions.values, y=top_regions.index, palette="YlOrBr_r")
    plt.title(f'{month}월 발생건수 상위 {top_n} 시군구')
    plt.xlabel('발생 건수')
    plt.ylabel('시군구')
    plt.tight_layout()
    plt.show()

import pandas as pd

# 예시: df_full 이 전체 데이터프레임이라고 가정
columns_to_keep = [
    'SIG_KOR_NM','피해면적_합계','발생원인_구분',
    '발생일시_전체','진화종료일시_전체','진화_소요시간_분','발생일시_요일','발생시간대',
    '진화_소요시간_분',
]

# 필요한 컬럼만 추출
df_cleaned = df_merged[columns_to_keep].copy()

# 결측값 확인
print(df_cleaned.isnull().sum())

# 데이터 미리보기
print(df_cleaned.head())

#따로 저장필요하면
"""
df_cleaned.save_csv('./정제된최종.csv', index=False, encoding='utf-8-sig')
print("\n✅ 최종 재보정 결과 저장 완료: '정제된최종.csv'")
"""